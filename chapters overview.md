0. **Abstract**

   *needs to be updated*

1. **Introduction**

   *half done, will be finished close to last*

   existing sections:

   - 1.1 Context
   - 1.2 Problem
   - 1.3 Our Approach

2. **Related Works**

   *a work in progress, needs to be mostly rewritten + a lot to read*

   existing sections:

   - 2.1 Code Completion Before Machine Learning
   - 2.2 Software Naturalness
   - 2.3 Conclusions from Further Experiments
   - 2.4 More Papers (name WIP)

3. **Completion in Pharo**

   *not started yet*

   ideas:

   - 3.1 overview of the pharo IDE and how completion works in general
   - 3.2 overview of the old completion (pre-AST)
   - 3.3 overview of the AST alphabetical completion and the role the sorter plays

4. **N-gram Background**

   *mostly ready but needs feedback*

   existing sections:

   - 4.1 N-gram Language Models
   - 4.2 N-grams
   - 4.3 Evaluating Models
   - 4.4 Smoothing
   - 4.5 Summary

5. **Proposed solution**

   *halfway done, needs feedback (i need to extend it and don't know with what)*

   existing sections:

   - 5.1 Background
   - 5.2 Unigram Sorting
   - 5.3 Bigram Sorting

6. **Evaluation**

   *not started yet*

   ideas:

   - 6.1 overview of evaluation strategies and why it's important
   - 6.2 description of the evaluation approach we are using
   - 6.3 description of the experiment
   - 6.4 results

7. **Conclusion**

   *not started yet, will be done when other chapters (besides introduction) are fully completed*