\chapter{Related Works}
\label{chap:RelatedWorks}

\section{Earlier Code Completion Systems}
\label{sec:RelatedWorks-EarlierSystems}
Standard code completions in IDEs used to only rely on language-specific pattern matching, i.e. sorting completions alphabetically based on the symbols already typed in. \cite{Robb08a}, however, showed code completion can be improved by using \notclear{program history}. \remove{In particular, }they managed to get good results by prioritising suggestions from recently modified method bodies, and even better results by using per-session vocabulary (changes of the last hour) and merging it with type-based completion.

According to \cite{Bruc09a}, up until 10 years ago code completions were exclusively based on \notclear{static type system of programming languages}. The authors countered that by implementing intelligent code completion systems that learned from examples and had a significantly better performance \remove{in terms of suggestions relevance} than \notclear{regular} completions \insertion{in terms of relevance of suggestions}. \badstyle{The implementations \remove{in particular} were:} the frequency based code completion (frequency of use of code), an association rule based completion, and the Best Matching Neighbours code completion (method calls of the closest source snippet found, using a \insertion{modified} k-nearest neighbours algorithm \remove{modification}), which was the main contribution of their paper. The BMN based implementation was integrated into Eclipse and demonstrated promising results. It was later extended by \cite{Prok15a}. \oz{Extended how? You can add a reference: (See \ref{sec:RelatedWorks-DeepLearning})}

\section{Software Naturalness}
\label{sec:RelatedWorks-SoftwareNaturalness}
\remove{In the paper that ultimately made a very big impact in the code completion research area, titled "On The Naturalness of Software", } \oz{I strongly recommend avoiding subjective statements like that one} \cite{Hind12a} compared source code to natural languages. They claim that code is even more repetitive, predictable and full of patterns than human languages. In the paper, they also argue that code can be modelled by statistical language models, which can be used to support software engineers. Their approach was based on capturing high-level statistical regularity at the n-gram level by taking n-1 previous tokens that are already entered into the text buffer, and attempting to guess the next token. Using this model, it is possible to estimate the most probable sequences of tokens and suggest the most relevant code completions to developers.

\remove{As mentioned above, }this work served as a \remove{sort of} catalyst for the following research using natural language \replace{approaches}{processing (NLP)} for source code. For instance, \cite{Tu14a} also learnt that code "has a high degree of localness, where identifiers (e.g. variable names) are repeated often within close distance" (\cite{Alla18a}). \remove{Thus, }they applied a cache mechanism that assigns higher probability to tokens that have been observed most recently, and \remove{were able to} \repetition{improve\insertion{d}} the results even further.

\cite{Nguy13a} \repetition{improved} the state-of-the-art n-gram \oz{You should be consistent and use either "N-gram" or "n-gram" throughout your thesis} approach by incorporating semantic information into code tokens, rather than treating them as text -- i.e. annotating each token with its data type and semantic role if available, which allowed them to \remove{even further} increase predictability \insertion{even further}. \remove{The experiment, however, was configured for Java and C\# only}. \oz{I'm not sure that it's a good idea to say that. Every experiment that you mentioned was done in some specific language. And all your experiments are only in Pharo. So what?}

\section{Deep Learning for Code Completion}
\label{sec:RelatedWorks-DeepLearning}
In the more recent years, researche\insertion{r}s started applying deep learning models such as deep recurrent neural networks \insertion{(RNN)}.

For instance, \cite{Hell19a} recorded the results of a case study of 15,000 completions (completion events) for VisualStudio. One of the conclustions \badstyle{they've} reached is that even though RNNs often outperform n-gram models in typical natural language settings, n-gram models are sometimes a better choice for modeling source code. For example, the deep learner is better at core method invocations but loses on third-party library calls, whereas the n-gram model naturally outperforms it on internal API calls but loses out on the other categories.

\cite{Prok15a} worked on an extensible inference engine for intelligent code completion systems, called PatternBased Bayesian Network (PBN). Eclipse Code Recommenders\remove{6} project adapted the PBN approach for their intelligent call completion. \badstyle{They've} also tested (evaluating quality, speed and model size) Best Matching Neighbour algorithm, using additional context information for more precise recommendations, and applying clustering techniques to improve model sizes. They\replace{'ve reached the following conclusions:}{conclude that} showing the developer hundreds of recommendations may be as ineffective as showing none, and intelligent code completions better target the needs of developers that are unfamiliar with an API.

\cite{Hell17a} introduced a \notclear{dynamically updatable, nested scope, unlimited vocabulary count-based N-gram model} \oz{OMG} which outperformed both the traditional N-gram models and the deep learning RNN and \notclear{LSTM} \oz{What is LSTM? This term was not introduced yet} models.

\cite{Li17a} developed an attention mechanism which exploits the parent-children information of \badstyle{the code AST}. As \notclear{correctly predicting} out-of-vocabulary (OoV) values in code completion \notclear{is largely unsuccessful}, the authors implemented a pointer mixture network which either generates a new value through an RNN component, or copies an OoV value from local context through a pointer component.

\cite{Rayc14a} implemented a tool called SLANG, which \replace{Ô¨Å}{fi}rst \oz{That's why you should not copy-paste from PDF} extracts \notclear{abstract histories} from the data. Then, these histories are fed to a language model such as an n-gram model or recurrent neural network model, which treats the histories as sentences in a natural language and learns probabilities for each sentence, \replace{not at all}{without} taking into consider\replace{ing}{ation} \badstyle{code AST} information.

\section{Existing Code Completion Systems in IDEs}
\label{sec:RelatedWorks-ExistingSystems}
The code completion system (Pythia) described by \cite{Svya19a} is part of the Intellicode extension used in the Visual Studio Code IDE to complete Python code. Pythia uses LSTM networks trained on long-range code contexts extracted from abstract syntax trees, which allows it to capture semantics carried by distant nodes and \badstyle{helps more successfully rank} the method and API recommendations for developers. \remove{As} Python is a dynamically typed language, \insertion{so} to \remove{be able to} \replace{leverage}{use} type information in Pythia they infer types at runtime based on static analysis of user patterns and add this information into the training sequence.

\cite{Asad14a} developed a tool called CSCC (context-sensitive code completion) which leverages contextual information to better support method call completion. \badstyle{CSCC, being an example-based completion tool, uses} tokenisation instead of deep parsing to collect method call usage patterns\replace{, as well as}{and} requires type information of the receiver object. The CSCC tool is available as an Eclipse plugin for the Java Editor. Execution time wise the tool showed the results roughly equal to the \repetition{state of the art}, but in terms of method call recommendation accuracy it outperformed the \repetition{state-of-the-art} approaches \oz{Again, be consistent, sometimes you write "state-of-the-art" and sometimes "state of the art"}, including BMN (the Best Matching Neighbours implementation from \cite{Bruc09a}).

CACHECA is a cache language model-based code completion tool for Eclipse's Java editor which was presented by \cite{Fran15a}; the tool is based on the cache language model described by \cite{Tu14a} and mentioned earlier in this chapter. According to \cite{Fran15a}, CACHECA greatly enhances Eclipse's built-in engine by incorporating both the corpus and locality statistics, especially when no type information is available.

\section{Summary}
\label{sec:RelatedWorks-Summary}
Here is a brief overview of the progress made in the area of code completion research and development in recent years:

\oz{Each item should start with a capital letter}
\begin{itemize}
    \item code completion tools used to only rely on language-specific pattern matching (i.e. by prefix), but around 10 years ago the idea of "intelligent" code completion that can learn from examples was popularised
    \item the software engineering approaches following this idea relied on frequency of use of code, contextual association, and hierarchical proximity
    \item from another perspective, source code was likened to natural languages because of its repetitiveness and patterns; the idea that source code can be modelled by statistical language models attracted more machine learning approaches for the task of improving code completion
    \item following that, a lot of code completion implementations using machine learning ignored such information as type and semantic meaning, and treated it as regular text, trying to infer relevant predictions from source code history alone
    \item these days, code completion systems that are actually being used by developers (such as plugins for IDEs) mostly combine both \notclear{software engineering approaches} \repetition{taking advantage of} semantic and contextual information and machine learning approaches \repetition{taking advantage of} source code patterns\insertion{.}
\end{itemize}